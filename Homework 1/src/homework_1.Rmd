---
title: "Homework 1"
subtitle: "Stat 597a: Spatial Models"
author: "Claire Kelling"
date: "Due September 28, 2017"
output: pdf_document
---

# Problem 1:
\textbf{Suppose we want to simulate a random vector $Y \sim N(\mu, \Sigma)$. If $\Sigma$ is symmetric and positive definite, it can be represented using the Cholesky decomposition
$\Sigma = LL^{T}$, where L is a lower triangular matrix. Consider the following
algorithm for simulating Y:}
\begin{itemize}
\item \textbf{Calculate the matrix L.}
\item \textbf{Sample $Z \sim N(0,I)$, where I is the n x n identity matrix.}
\item \textbf{Let $Y= \mu+LZ$.}
\end{itemize}
\textbf{Part a: }
\textbf{Show that Y generated in this way has the correct distribution. You may use the fact that a linear function of a multivariate normal random variable is again multivariate normal; just show the mean and variance are correct.}

First, I will show the mean of this Y. 
$$ E(Y) = E(\mu + LZ) = \mu + E(LZ) = \mu+ LE(Z) = \mu + 0 = \mu $$
Now, I will check the variance of Y. 
$$ Var(Y) = Var(\mu +LZ) + Var(LZ) = LVar(Z)L^{T} = LIL^{T}=LL^{T}=\Sigma$$
As stated in the problem, since a linear function of a multivariate normal random variable is also a multivariate normal, since I have verified that the mean and variance are correct, I have shown that Y generated in this way has the correct distribution of $Y\sim N(\mu, \Sigma)$. 

\textbf{Part b: }
\textbf{Write a function or a few lines of code in R to implement this method for arguments mu and Sigma. You may use the built-in function chol for the Cholesky decomposition and rnorm to generate Z.}

I have included my function in the code shown below. 

```{r multinorm}
#creating a function with mu and Sigma inputs to generate Y~N(mu,Sigma) using N(0,1)
multi_norm <- function(mu, Sigma){
  #I'm including these first few lines of code to make sure that it is positive   
  #semi-definite
  #Sigma <- Sigma2
  chol_mat = chol(Sigma, pivot=TRUE)
  pivot = attr(chol_mat, "pivot")
  L = chol_mat[,order(pivot)]
  set.seed(3)
  Z = rnorm(nrow(Sigma),0,1)
  Y = mu + t(L)%*%Z
}

```


## Part c:
\textbf{For a mean and covariance function of your choosing, use your code from (b) and make a few plots illustrating realizations of a Gaussian process on [0, 1], but changing the different parameters in the model. These differences will be easier to see if you keep the same Z sample but just change mu and Sigma.}

For this problem, I will create 3 realizations of a GP on [0,1] and changing several different parameters in the model. I set the seed in my mulinorm function so that Z does not vary, only mu and Sigma inputs will change. 

For the red line on the bottom, we see that this is an example of a Standard Brownian Bridge on the interval [0,1]. It has the covariance matrix given by $\Sigma_{ij}=min(t_i,t_j)\times(1-max(t_i,t_j))$. It has mean 0. The blue line slightly above this has a mean of 5, which is clearly seen in the plot, and $Sigma=diag(1)$ so there is only variation around 5. For the top line, it has mean 15, which is where it tends to hang around on the left side of the graph but $\Sigma$ is a matrix of all one's, so it doesn't just fluctuate around 5, as with the second line mentioned. 

```{r 1c, echo=FALSE, warning= FALSE}

# Problem 1c

# Defining how many points I want on the interval- 500 equally spaced
n <- 500
# I want 3 simulations of a Gaussian Process
nsim <- 3
# I want a Gaussian Process on [0,1]
tmax <- 1
# Initializing a matrix to store all of the realizations of different Gaussian Processes
y.mat <- matrix(NA, n+1, nsim)
# creating a x-vector for the x-axis on the plots, will be used in some of the functions 
# for the mean and the variance
x.vec <- (0:n)/n*tmax

#Mean Functions
mu1 <- rep(5,n+1) 
mu2 <- rep(0,n+1)
mu3 <- rep(15,n+1)

#Covariance Functions
#diagonal covariance
Sigma1 <- diag(1,n+1)
# Standard Brownian Bridge Process
Sigma2 <- matrix(NA,nrow=length(x.vec),ncol=length(x.vec))
#x.vec <- x.vec[-c(1,501)]
for(i in 1:length(x.vec)){
  for(j in 1:length(x.vec)){
    Sigma2[i,j]=min(x.vec[i],x.vec[j])*(1-max(x.vec[i],x.vec[j]))
  }
}
Sigma3 <- matrix(1, nrow=501,ncol=501)


y.mat[,1] <- multi_norm(mu1, Sigma1)
y.mat[,2] <- multi_norm(mu2, Sigma2)
y.mat[,3] <- multi_norm(mu3, Sigma3)

matplot(x.vec, y.mat, type = "l", col=c(4,2,3),lwd=2, xlab = "t", ylab = "X(t)", 
        lty = c(1,3,5), main = "Plot of my 3 realizations of a GP")

```


# Problem 2
\textbf{The file CAtemps.RData contains two R objects of class SpatialPointsDataFrame,
called CAtemp and CAgrid. CAtemp contains average temperatures from 1961-
1990 at 200 locations (latitude and longitude) in California in degrees Fahren-
heit, along with their elevations in meters. CAgrid contains elevations in meters
over a grid of locations. I've given you some code to get started with this data
in HW1.R.}

\textbf{Consider the following model for the temperature data. $$Y_i = \mu(s_i;\beta)+e(s_i; \sigma^2, \rho, \tau)$$ where $\mu(s;\beta) = \beta_0 + \beta_1\text{Longitude}(s)+\beta_2\text{Latitude}(s)+\beta_3\text{Elevation}(s) \text{ and } e(s_i; \sigma^2, \rho, \tau)$ is a zero mean stationary Gaussian process with exponential covariance function.}

\textbf{Another way of writing this is as $$ Y_i = \mu(s_i;\beta) + Z(s_i;\sigma^2,\rho) + \epsilon_i $$ where now Z is a mean zero Gaussian process like $e$ but without the nugget term, and the $\epsilon_i \text{ are iid } N(0,\tau^2)$, indepdendent of Z. This is important because we want to predict $\mu(s_i;\beta) + Z(s_i;\sigma^2,\rho)$ \textit{without} the measurement error.}

```{r exploratory_analysis, include=FALSE}
library(sp)
library(gstat)
library(fields)
library(classInt)
library(maps)

load("C:/Users/ckell/OneDrive/Penn State/2017-2018/597/spatial_statistics_597/Homework 1/data/CAtemps.RData")

ploteqc <- function(spobj, z, breaks, ...){
  pal <- tim.colors(length(breaks)-1)
  fb <- classIntervals(z, n = length(pal), 
                       style = "fixed", fixedBreaks = breaks)
  col <- findColours(fb, pal)
  plot(spobj, col = col, ...)
  image.plot(legend.only = TRUE, zlim = range(breaks), col = pal)
}

## Plotting

range(CAtemp$avgtemp)
breaks <- 40:75
x11()
ploteqc(CAtemp, CAtemp$avgtemp, breaks, pch = 19)
map("county", region = "california", add = TRUE)
title(main = "Average Annual Temperatures, 1961-1990, Degrees F")

range(CAgrid$elevation)
breaks <- seq(-100, 3600, by = 100)
ploteqc(CAgrid, CAgrid$elevation, breaks, pch = 19)
map("county", region = "california", add = TRUE)
title(main = "Elevations at prediction locations, m")
```


\textbf{Part a: }
\textbf{Using the CAtemp data, form a preliminary estimate of $\beta$ using ordinary least squares and make a color plot of the residuals. Include your estimates and plot.}
```{r 2a, echo=FALSE}
##
#creating preliminary estimate
##
head(CAtemp)
#I need to convert it to a dataframe to be able to access the lat/lon coordinates
CAtemp_df <- as.data.frame(CAtemp)
head(CAtemp_df)
#fitting the preliminary linear model
linmod <- lm(avgtemp~elevation + lon + lat, data= CAtemp_df)
summary(linmod) #ignore standard errors!

#storing the residuals so I can plot them
fitted <- predict(linmod, newdata=CAtemp_df, na.action = na.pass)
ehat <- CAtemp_df$avgtemp - fitted #residuals

#making the residuals a variable in the dataframe
CAtemp_df$ehat <- ehat
CAtemp_df$ehatabs <- abs(ehat)
coordinates(CAtemp_df) <-  c("lon", "lat") 

range(CAtemp_df$ehat)
breaks <- seq(-7, 7, by = 0.1)
ploteqc(CAtemp_df, CAtemp_df$ehat, breaks, pch = 19)
map("county", region = "california", add = TRUE)
title(main = "Residuals")

breaks <- seq(0, 7, by = 0.1)
ploteqc(CAtemp_df, CAtemp_df$ehatabs, breaks, pch = 19)
map("county", region = "california", add = TRUE)
title(main = "Absolute Value of the Residuals")
```


\textbf{Part b: }
\textbf{Estimate the variogram nonparametrically and then fit the exponential variogram to it using weighted least squares. Make and include a plot of the nonparametric and parametric variogram functions. Also store your parameter estimates and report them.}
```{r 2b, echo=FALSE}

#converting back to dataframe
CAtemp_df <- as.data.frame(CAtemp_df)

##  Nonparametric estimation of the variogram
vg <- variogram(ehat ~ 1, data = CAtemp_df, width=75)
plot(vg, xlab = "Distance", ylab = "Semi-variogram estimate", width=5)

##  Fitting the variogram parametrically
fitvg <- fit.variogram(vg, vgm(1, "Exp", 500, 0.05))
print(fitvg)
s2.hat <- fitvg$psill[2]
rho.hat <- fitvg$range[2]
tau2.hat <- fitvg$psill[1]

plot(vg, fitvg, xlab = "Distance", ylab = "Semi-variogram estimate")

```


\textbf{Part c: }
\textbf{We will now form the GLS estimate of $\beta$ by hand, rather than using the gls function. (This function doesn't handle longitude and latitude well, and I also want to give you some practice with matrix calculations in R.)}
\begin{itemize}
\item Use the rdist.earth function in fields to create a matrix of distances (in miles) between pairs of locations in CAtemp.
\item Create the covariance matrix, plugging in your estimates from the fitted variogram. \textit{Hint: Sum two matrices, one without a nugget and one using the diag function to create the matrix $\tau^2I$}.
\item Invert the covariance matrix and store it for later reference.
\item Create the X matrix. \textit{Hint: Use cbind.}
\item Put all the pieces together to form $\hat{\beta}_{GLS}$
\end{itemize}

```{r 2c, echo= FALSE}
rownames(CAtemp_df) <- c()
# Use the rdist.earth function in fields to create a matrix of distances (in miles) 
# between pairs of locations in CAtemp.
#   There are some entries on the diagonal that are not zero, but this is also true
#   in the case in the documentation, so I won't worry too much about it!
dist_mat <- rdist.earth(CAtemp_df[,3:4], miles = TRUE)

# Create the covariance matrix, plugging in your estimates from the fitted variogram.
mat1 <- diag(tau2.hat, ncol = 200, nrow=200)
#mat2 <- Matern(dist_mat, scale = s2.hat, range = rho.hat, smoothness = 0.5)
mat2 <- Exponential(dist_mat, phi=s2.hat, range=rho.hat)
# phi = Marginal variance, Exponential: phi* exp( -d/range)
cov <- mat1+mat2


# Invert the covariance matrix and store it for later reference.
inv <- solve(cov)

# Create the X matrix. Hint: Use cbind.
X <- cbind(rep(1,nrow(CAtemp_df)), CAtemp_df[,2:4])


```


\textbf{Part d: }
\textbf{Calculate and plot the EBLUP of $\mu+Z$ at the locations in CAgrid, plugging in your estimates from (b) and (c). Calculate and plot the (estimated) standard error of Z at each prediction location.}
```{r 2d, echo=FALSE}

```





# Appendix

```{r appendix, ref.label='1c', eval = FALSE}
```
```{r appendix2, ref.label='exploratory_analysis', eval = FALSE}
```
```{r appendix3, ref.label='2a', eval = FALSE}
```
```{r appendix4, ref.label='2b', eval = FALSE}
```
```{r appendix5, ref.label='2c', eval = FALSE}
```
```{r appendix6, ref.label='2d', eval = FALSE}
```
